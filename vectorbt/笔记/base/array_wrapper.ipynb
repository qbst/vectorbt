{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类继承关系\n",
    "```mermaid\n",
    "classDiagram\n",
    "    class Configured\n",
    "    class PandasIndexer\n",
    "    class ColumnGrouper\n",
    "    class ArrayWrapper\n",
    "    class Wrapping\n",
    "    \n",
    "    Configured <|-- ArrayWrapper\n",
    "    PandasIndexer <|-- ArrayWrapper\n",
    "    Configured <|-- Wrapping\n",
    "    PandasIndexer <|-- Wrapping\n",
    "    AttrResolver <|-- Wrapping\n",
    "\n",
    "    ArrayWrapper o-- ColumnGrouper : has\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class ArrayWrapper(Configured, PandasIndexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__init__`\n",
    "```python\n",
    "    def __init__(self,\n",
    "                 index: tp.IndexLike,                           # 行索引，支持类似pandas索引的对象\n",
    "                 columns: tp.IndexLike,                         # 列索引，支持类似pandas索引的对象\n",
    "                 ndim: int,                      # 数组维度数量，通常为1（Series）或2（DataFrame）\n",
    "                 freq: tp.Optional[tp.FrequencyLike] = None,    # 时间序列频率，可选\n",
    "                 column_only_select: tp.Optional[bool] = None,  # 是否仅对列进行索引，可选\n",
    "                 group_select: tp.Optional[bool] = None,        # 是否对分组进行索引，可选\n",
    "                 grouped_ndim: tp.Optional[int] = None,         # 分组后的维度数量，可选\n",
    "                 **kwargs) -> None:                             # 传递给ColumnGrouper的额外参数\n",
    "        config = dict(\n",
    "            index=index,\n",
    "            columns=columns,\n",
    "            ndim=ndim,\n",
    "            freq=freq,\n",
    "            column_only_select=column_only_select,\n",
    "            group_select=group_select,\n",
    "            grouped_ndim=grouped_ndim,\n",
    "        )\n",
    "\n",
    "        checks.assert_not_none(index)\n",
    "        checks.assert_not_none(columns)\n",
    "        checks.assert_not_none(ndim)\n",
    "        \n",
    "        if not isinstance(index, pd.Index):\n",
    "            index = pd.Index(index) \n",
    "        if not isinstance(columns, pd.Index):\n",
    "            columns = pd.Index(columns) \n",
    "\n",
    "        self._index = index \n",
    "        self._columns = columns\n",
    "        self._ndim = ndim\n",
    "        self._freq = freq\n",
    "        self._column_only_select = column_only_select\n",
    "        self._group_select = group_select\n",
    "        self._grouper = ColumnGrouper(columns, **kwargs)\n",
    "        self._grouped_ndim = grouped_ndim\n",
    "\n",
    "        PandasIndexer.__init__(self) \n",
    "        Configured.__init__(self, **merge_dicts(config, self._grouper._config)) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indexing_func_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### settings['array_wrapper']\n",
    "```python\n",
    "array_wrapper=dict(\n",
    "    column_only_select=False,  # 不仅选择列\n",
    "    group_select=True,  # 启用组选择\n",
    "    freq=None,  # 频率默认为None\n",
    "    silence_warnings=False  # 不静默警告\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regroup\n",
    "```python\n",
    "def regroup(self: ArrayWrapperT, group_by: tp.GroupByLike, **kwargs) -> ArrayWrapperT:\n",
    "    \"\"\"\n",
    "    重新分组对象\n",
    "    \n",
    "    根据新的分组依据创建新的ArrayWrapper实例。只有在分组发生变化时\n",
    "    才创建新实例，否则返回自身以保持缓存有效性。\n",
    "    \n",
    "    Args:\n",
    "        group_by: 新的分组依据\n",
    "        **kwargs: 传递给replace方法的额外参数\n",
    "        \n",
    "    Returns:\n",
    "        ArrayWrapperT: 重新分组后的ArrayWrapper实例\n",
    "        \n",
    "    Examples:\n",
    "        >>> wrapper = ArrayWrapper(\n",
    "        ...     index=pd.Index(['A', 'B']),\n",
    "        ...     columns=pd.Index(['X', 'Y', 'Z']),\n",
    "        ...     ndim=2\n",
    "        ... )\n",
    "        >>> # 重新分组\n",
    "        >>> grouped = wrapper.regroup(['G1', 'G1', 'G2'])\n",
    "        >>> print(grouped.grouper.get_group_count())\n",
    "        2\n",
    "        \n",
    "        # 取消分组\n",
    "        >>> ungrouped = grouped.regroup(None)\n",
    "        >>> print(ungrouped.grouper.is_grouped())\n",
    "        False\n",
    "    \"\"\"\n",
    "    if self.grouper.is_grouping_changed(group_by=group_by):\n",
    "        self.grouper.check_group_by(group_by=group_by)\n",
    "        grouped_ndim = None\n",
    "        if self.grouper.is_grouped(group_by=group_by):\n",
    "            if not self.grouper.is_group_count_changed(group_by=group_by):\n",
    "                grouped_ndim = self.grouped_ndim\n",
    "        return self.replace(grouped_ndim=grouped_ndim, group_by=group_by, **kwargs)\n",
    "    return self  # important for keeping cache\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "@cached_method\n",
    "def indexing_func_meta(self: ArrayWrapperT,\n",
    "                        pd_indexing_func: tp.PandasIndexingFunc,\n",
    "                        index: tp.Optional[tp.IndexLike] = None,\n",
    "                        columns: tp.Optional[tp.IndexLike] = None,\n",
    "                        column_only_select: tp.Optional[bool] = None,\n",
    "                        group_select: tp.Optional[bool] = None,\n",
    "                        group_by: tp.GroupByLike = None) -> IndexingMetaT:\n",
    "    from vectorbt._settings import settings\n",
    "    array_wrapper_cfg = settings['array_wrapper']\n",
    "\n",
    "    if column_only_select is None:\n",
    "        column_only_select = self.column_only_select\n",
    "    if column_only_select is None:\n",
    "        column_only_select = array_wrapper_cfg['column_only_select']\n",
    "    if group_select is None:\n",
    "        group_select = self.group_select\n",
    "    if group_select is None:\n",
    "        group_select = array_wrapper_cfg['group_select']\n",
    "    _self = self.regroup(group_by)\n",
    "    group_select = group_select and _self.grouper.is_grouped()\n",
    "    if index is None:\n",
    "        index = _self.index\n",
    "    if not isinstance(index, pd.Index):\n",
    "        index = pd.Index(index)\n",
    "    if columns is None:\n",
    "        if group_select:\n",
    "            columns = _self.grouper.get_columns()\n",
    "        else:\n",
    "            columns = _self.columns\n",
    "    if not isinstance(columns, pd.Index):\n",
    "        columns = pd.Index(columns)\n",
    "    if group_select:\n",
    "        # Groups as columns\n",
    "        i_wrapper = ArrayWrapper(index, columns, _self.get_ndim())\n",
    "    else:\n",
    "        # Columns as columns\n",
    "        i_wrapper = ArrayWrapper(index, columns, _self.ndim)\n",
    "    n_rows = len(index)\n",
    "    n_cols = len(columns)\n",
    "\n",
    "    if column_only_select:\n",
    "        if i_wrapper.ndim == 1:\n",
    "            raise IndexingError(\"Columns only: This object already contains one column of data\")\n",
    "        try:\n",
    "            col_mapper = pd_indexing_func(i_wrapper.wrap_reduced(np.arange(n_cols), columns=columns))\n",
    "        except pd.core.indexing.IndexingError as e:\n",
    "            warnings.warn(\"Columns only: Make sure to treat this object \"\n",
    "                            \"as a Series of columns rather than a DataFrame\", stacklevel=2)\n",
    "            raise e\n",
    "        if checks.is_series(col_mapper):\n",
    "            new_columns = col_mapper.index\n",
    "            col_idxs = col_mapper.values\n",
    "            new_ndim = 2\n",
    "        else:\n",
    "            new_columns = columns[[col_mapper]]\n",
    "            col_idxs = col_mapper\n",
    "            new_ndim = 1\n",
    "        new_index = index\n",
    "        idx_idxs = np.arange(len(index))\n",
    "    else:\n",
    "        idx_mapper = pd_indexing_func(i_wrapper.wrap(\n",
    "            np.broadcast_to(np.arange(n_rows)[:, None], (n_rows, n_cols)),\n",
    "            index=index,\n",
    "            columns=columns\n",
    "        ))\n",
    "        if i_wrapper.ndim == 1:\n",
    "            if not checks.is_series(idx_mapper):\n",
    "                raise IndexingError(\"Selection of a scalar is not allowed\")\n",
    "            idx_idxs = idx_mapper.values\n",
    "            col_idxs = 0\n",
    "        else:\n",
    "            col_mapper = pd_indexing_func(i_wrapper.wrap(\n",
    "                np.broadcast_to(np.arange(n_cols), (n_rows, n_cols)),\n",
    "                index=index,\n",
    "                columns=columns\n",
    "            ))\n",
    "            if checks.is_frame(idx_mapper):\n",
    "                idx_idxs = idx_mapper.values[:, 0]\n",
    "                col_idxs = col_mapper.values[0]\n",
    "            elif checks.is_series(idx_mapper):\n",
    "                one_col = np.all(col_mapper.values == col_mapper.values.item(0))\n",
    "                one_idx = np.all(idx_mapper.values == idx_mapper.values.item(0))\n",
    "                if one_col and one_idx:\n",
    "                    # One index and one column selected, multiple times\n",
    "                    raise IndexingError(\"Must select at least two unique indices in one of both axes\")\n",
    "                elif one_col:\n",
    "                    # One column selected\n",
    "                    idx_idxs = idx_mapper.values\n",
    "                    col_idxs = col_mapper.values[0]\n",
    "                elif one_idx:\n",
    "                    # One index selected\n",
    "                    idx_idxs = idx_mapper.values[0]\n",
    "                    col_idxs = col_mapper.values\n",
    "                else:\n",
    "                    raise IndexingError\n",
    "            else:\n",
    "                raise IndexingError(\"Selection of a scalar is not allowed\")\n",
    "        new_index = index_fns.get_index(idx_mapper, 0)\n",
    "        if not isinstance(idx_idxs, np.ndarray):\n",
    "            # One index selected\n",
    "            new_columns = index[[idx_idxs]]\n",
    "        elif not isinstance(col_idxs, np.ndarray):\n",
    "            # One column selected\n",
    "            new_columns = columns[[col_idxs]]\n",
    "        else:\n",
    "            new_columns = index_fns.get_index(idx_mapper, 1)\n",
    "        new_ndim = idx_mapper.ndim\n",
    "\n",
    "    if _self.grouper.is_grouped():\n",
    "        # Grouping enabled\n",
    "        if np.asarray(idx_idxs).ndim == 0:\n",
    "            raise IndexingError(\"Flipping index and columns is not allowed\")\n",
    "\n",
    "        if group_select:\n",
    "            # Selection based on groups\n",
    "            # Get indices of columns corresponding to selected groups\n",
    "            group_idxs = col_idxs\n",
    "            group_idxs_arr = reshape_fns.to_1d_array(group_idxs)\n",
    "            group_start_idxs = _self.grouper.get_group_start_idxs()[group_idxs_arr]\n",
    "            group_end_idxs = _self.grouper.get_group_end_idxs()[group_idxs_arr]\n",
    "            ungrouped_col_idxs = get_ranges_arr(group_start_idxs, group_end_idxs)\n",
    "            ungrouped_columns = _self.columns[ungrouped_col_idxs]\n",
    "            if new_ndim == 1 and len(ungrouped_columns) == 1:\n",
    "                ungrouped_ndim = 1\n",
    "                ungrouped_col_idxs = ungrouped_col_idxs[0]\n",
    "            else:\n",
    "                ungrouped_ndim = 2\n",
    "\n",
    "            # Get indices of selected groups corresponding to the new columns\n",
    "            # We could do _self.group_by[ungrouped_col_idxs] but indexing operation may have changed the labels\n",
    "            group_lens = _self.grouper.get_group_lens()[group_idxs_arr]\n",
    "            ungrouped_group_idxs = np.full(len(ungrouped_columns), 0)\n",
    "            ungrouped_group_idxs[group_lens[:-1]] = 1\n",
    "            ungrouped_group_idxs = np.cumsum(ungrouped_group_idxs)\n",
    "\n",
    "            return _self.replace(\n",
    "                index=new_index,\n",
    "                columns=ungrouped_columns,\n",
    "                ndim=ungrouped_ndim,\n",
    "                grouped_ndim=new_ndim,\n",
    "                group_by=new_columns[ungrouped_group_idxs]\n",
    "            ), idx_idxs, group_idxs, ungrouped_col_idxs\n",
    "\n",
    "        # Selection based on columns\n",
    "        col_idxs_arr = reshape_fns.to_1d_array(col_idxs)\n",
    "        return _self.replace(\n",
    "            index=new_index,\n",
    "            columns=new_columns,\n",
    "            ndim=new_ndim,\n",
    "            grouped_ndim=None,\n",
    "            group_by=_self.grouper.group_by[col_idxs_arr]\n",
    "        ), idx_idxs, col_idxs, col_idxs\n",
    "\n",
    "    # Grouping disabled\n",
    "    return _self.replace(\n",
    "        index=new_index,\n",
    "        columns=new_columns,\n",
    "        ndim=new_ndim,\n",
    "        grouped_ndim=None,\n",
    "        group_by=None\n",
    "    ), idx_idxs, col_idxs, col_idxs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class Wrapping(Configured, PandasIndexer, AttrResolver)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
