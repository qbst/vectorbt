{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类继承关系\n",
    "```mermaid\n",
    "classDiagram\n",
    "    %% 元类层次结构\n",
    "    class dict\n",
    "    class symbol_dict\n",
    "    class Configured\n",
    "    class PandasIndexer\n",
    "    class AttrResolver\n",
    "    class Wrapping\n",
    "    class MetaPlotsBuilderMixin {\n",
    "        <<metaclass>>\n",
    "    }\n",
    "    class MetaStatsBuilderMixin {\n",
    "        <<metaclass>>\n",
    "    }\n",
    "    class MetaData {\n",
    "        <<metaclass>>\n",
    "    }\n",
    "\n",
    "    class StatsBuilderMixin\n",
    "    class PlotsBuilderMixin\n",
    "    class Data\n",
    "\n",
    "    \n",
    "    %% 继承关系\n",
    "    dict <|-- symbol_dict\n",
    "    Wrapping <|-- Data\n",
    "\n",
    "    Configured <|-- Wrapping\n",
    "    PandasIndexer <|-- Wrapping\n",
    "    AttrResolver <|-- Wrapping\n",
    "\n",
    "    MetaPlotsBuilderMixin <|-- PlotsBuilderMixin: metaclass\n",
    "    MetaPlotsBuilderMixin <|-- MetaData: metaclass\n",
    "    MetaStatsBuilderMixin <|-- MetaData: metaclass\n",
    "    MetaStatsBuilderMixin <|-- StatsBuilderMixin: metaclass\n",
    "\n",
    "    StatsBuilderMixin <|-- Data\n",
    "    PlotsBuilderMixin <|-- Data\n",
    "    MetaData <|-- Data: metaclass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class symbol_dict(dict)\n",
    "用于存储以金融符号为键的配置参数。例如：\n",
    "```python\n",
    "# 为不同符号设置不同的起始值\n",
    "start_values = symbol_dict({\n",
    "    'AAPL': 1000000,    # 苹果股票起始投资100万\n",
    "    'GOOGL': 500000     # 谷歌股票起始投资50万\n",
    "})\n",
    "\n",
    "# 为不同符号设置不同的时间范围\n",
    "start_dates = symbol_dict({\n",
    "    'AAPL': '2020-01-01',\n",
    "    'GOOGL': '2021-01-01'\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class MetaData(type(StatsBuilderMixin), type(PlotsBuilderMixin))\n",
    "将统计构建器元类 `MetaStatsBuilderMixin` 和图表构建器元类 `MetaPlotsBuilderMixin` 整合为一个元类。\n",
    "```python\n",
    "class MetaData(type(StatsBuilderMixin), type(PlotsBuilderMixin)):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class Data(Wrapping, StatsBuilderMixin, PlotsBuilderMixin, metaclass=MetaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__init__`\n",
    "参数：\n",
    "- `wrapper (ArrayWrapper)`: 数组包装器，提供统一的数组操作接口\n",
    "- `data (tp.Data)`: 数据字典，以符号为键，pandas对象为值\n",
    "- `tz_localize (tp.TimezoneLike, optional)`: 时区本地化参数\n",
    "- `tz_convert (tp.TimezoneLike, optional)`: 时区转换参数  \n",
    "- `missing_index (str)`: 索引缺失处理策略 ('nan', 'drop', 'raise')\n",
    "- `missing_columns (str)`: 列缺失处理策略 ('nan', 'drop', 'raise')\n",
    "- `download_kwargs (dict)`: 下载时使用的关键字参数\n",
    "- `**kwargs`: 传递给父类的额外参数\n",
    "\n",
    "初始化过程：\n",
    "- 调用 `Wrapping` 父类初始化，设置数组包装器\n",
    "- 调用 `StatsBuilderMixin` 初始化，启用统计功能\n",
    "- 调用 `PlotsBuilderMixin` 初始化，启用图表功能\n",
    "- 验证数据字典 `data` 的格式和一致性\n",
    "- 存储配置参数为属性\n",
    "```python\n",
    "def __init__(self,\n",
    "                wrapper: ArrayWrapper,\n",
    "                data: tp.Data,\n",
    "                tz_localize: tp.Optional[tp.TimezoneLike],\n",
    "                tz_convert: tp.Optional[tp.TimezoneLike],\n",
    "                missing_index: str,\n",
    "                missing_columns: str,\n",
    "                download_kwargs: dict,\n",
    "                **kwargs) -> None:\n",
    "    Wrapping.__init__(\n",
    "        self,\n",
    "        wrapper,\n",
    "        data=data,\n",
    "        tz_localize=tz_localize,\n",
    "        tz_convert=tz_convert,\n",
    "        missing_index=missing_index,\n",
    "        missing_columns=missing_columns,\n",
    "        download_kwargs=download_kwargs,\n",
    "        **kwargs\n",
    "    )\n",
    "    StatsBuilderMixin.__init__(self)\n",
    "    PlotsBuilderMixin.__init__(self)\n",
    "\n",
    "    # 验证数据参数必须是字典类型\n",
    "    checks.assert_instance_of(data, dict)\n",
    "    # 验证所有数据项具有相同的元数据（索引、列等）\n",
    "    for k, v in data.items():\n",
    "        # 检查每个数据项与第一个数据项的元数据是否一致\n",
    "        checks.assert_meta_equal(v, data[list(data.keys())[0]])\n",
    "        \n",
    "    self._data = data\n",
    "    self._tz_localize = tz_localize\n",
    "    self._tz_convert = tz_convert \n",
    "    self._missing_index = missing_index\n",
    "    self._missing_columns = missing_columns\n",
    "    self._download_kwargs = download_kwargs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indexing_func\n",
    "由基类 `Wrapping` 使用，可以对 `Data` 实例进行 pandas 风格的索引操作，如 `.loc`、`.iloc`、切片等。\n",
    "\n",
    "参考 [indexing.ipynb](../base/indexing.ipynb)。\n",
    "```python\n",
    "def indexing_func(self: DataT, pd_indexing_func: tp.PandasIndexingFunc, **kwargs) -> DataT:\n",
    "    # 对数组包装器执行索引操作，获取新的包装器实例\n",
    "    new_wrapper = pd_indexing_func(self.wrapper)\n",
    "    # 对数据字典中每个pandas对象执行相同的索引操作\n",
    "    new_data = {k: pd_indexing_func(v) for k, v in self.data.items()}\n",
    "    # 创建并返回新的Data实例，保持其他配置不变\n",
    "    return self.replace(\n",
    "        wrapper=new_wrapper,\n",
    "        data=new_data\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### align_index\n",
    "统一 `data` 不同符号数据中的时间索引。\n",
    "\n",
    "参数：\n",
    "- `data (tp.Data)`: 待对齐的数据字典，键为符号，值为pandas对象\n",
    "- `missing (str)`\n",
    "  - `'nan'`: 将缺失的数据点设置为NaN\n",
    "  - `'drop'`: 删除缺失的数据点\n",
    "  - `'raise'`: 遇到不匹配时抛出异常\n",
    "```python\n",
    "@classmethod\n",
    "def align_index(cls, data: tp.Data, missing: str = 'nan') -> tp.Data:\n",
    "    if len(data) == 1:\n",
    "        return data\n",
    "\n",
    "    index = None\n",
    "    for k, v in data.items():\n",
    "        if index is None:\n",
    "            index = v.index\n",
    "        else:\n",
    "            if len(index.intersection(v.index)) != len(index.union(v.index)):\n",
    "                if missing == 'nan':\n",
    "                    warnings.warn(\"Symbols have mismatching index. \"\n",
    "                                    \"Setting missing data points to NaN.\", stacklevel=2)\n",
    "                    index = index.union(v.index) # 使用并集索引\n",
    "                elif missing == 'drop':\n",
    "                    warnings.warn(\"Symbols have mismatching index. \"\n",
    "                                    \"Dropping missing data points.\", stacklevel=2)\n",
    "                    index = index.intersection(v.index) # 使用交集索引\n",
    "                elif missing == 'raise':\n",
    "                    raise ValueError(\"Symbols have mismatching index\")\n",
    "                else:\n",
    "                    raise ValueError(f\"missing='{missing}' is not recognized\")\n",
    "\n",
    "    new_data = {k: v.reindex(index=index) for k, v in data.items()}\n",
    "    return new_data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vectorbt.data.base import Data\n",
    "\n",
    "data = {\n",
    "    'AAPL': pd.Series([100, 101, 102], index=['2023-01-01', '2023-01-02', '2023-01-03']),\n",
    "    'GOOGL': pd.Series([2000, 2010], index=['2023-01-01', '2023-01-03'])  # 缺少01-02\n",
    "}\n",
    "\n",
    "# 使用'nan'策略\n",
    "aligned = Data.align_index(data, missing='nan')\n",
    "print(aligned)  # GOOGL在2023-01-02处为NaN\n",
    "\n",
    "# 使用'drop'策略\n",
    "aligned = Data.align_index(data, missing='drop') \n",
    "print(aligned)  # 只保留01-01和01-03两个日期\n",
    "\n",
    "# 使用'raise'策略\n",
    "try:\n",
    "    aligned = Data.align_index(data, missing='raise')\n",
    "except ValueError:\n",
    "    print(\"索引不匹配，抛出异常\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### align_columns\n",
    "统一 `data` 不同符号数据中的列。\n",
    "\n",
    "参数：\n",
    "- `data (tp.Data)`: 待对齐的数据字典，键为符号，值为pandas对象\n",
    "- `missing (str)`\n",
    "  - `'nan'`: 将缺失的数据点设置为NaN\n",
    "  - `'drop'`: 删除缺失的数据点\n",
    "  - `'raise'`: 遇到不匹配时抛出异常\n",
    "```python\n",
    "@classmethod\n",
    "def align_columns(cls, data: tp.Data, missing: str = 'raise') -> tp.Data:\n",
    "    if len(data) == 1:\n",
    "        return data\n",
    "\n",
    "    columns = None\n",
    "    multiple_columns = False\n",
    "    name_is_none = False\n",
    "    for k, v in data.items():\n",
    "        if isinstance(v, pd.Series):\n",
    "            if v.name is None:\n",
    "                name_is_none = True\n",
    "            v = v.to_frame()\n",
    "        else:\n",
    "            multiple_columns = True\n",
    "        if columns is None:\n",
    "            columns = v.columns\n",
    "        else:\n",
    "            if len(columns.intersection(v.columns)) != len(columns.union(v.columns)):\n",
    "                if missing == 'nan':\n",
    "                    warnings.warn(\"Symbols have mismatching columns. \"\n",
    "                                    \"Setting missing data points to NaN.\", stacklevel=2)\n",
    "                    columns = columns.union(v.columns)\n",
    "                elif missing == 'drop':\n",
    "                    warnings.warn(\"Symbols have mismatching columns. \"\n",
    "                                    \"Dropping missing data points.\", stacklevel=2)\n",
    "                    columns = columns.intersection(v.columns)\n",
    "                elif missing == 'raise':\n",
    "                    raise ValueError(\"Symbols have mismatching columns\")\n",
    "                else:\n",
    "                    raise ValueError(f\"missing='{missing}' is not recognized\")\n",
    "\n",
    "    new_data = {}\n",
    "    for k, v in data.items():\n",
    "        if isinstance(v, pd.Series):\n",
    "            v = v.to_frame()\n",
    "        v = v.reindex(columns=columns)\n",
    "        if not multiple_columns:\n",
    "            v = v[columns[0]]\n",
    "            if name_is_none:\n",
    "                v = v.rename(None)\n",
    "        new_data[k] = v\n",
    "    return new_data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vectorbt.data.base import Data\n",
    "\n",
    "data = {\n",
    "    'AAPL': pd.DataFrame({\n",
    "        'Open': [100, 101], 'High': [102, 103], \n",
    "        'Low': [99, 100], 'Close': [101, 102], 'Volume': [1000, 1100]\n",
    "    }),\n",
    "    'GOOGL': pd.DataFrame({\n",
    "        'Close': [2000, 2010], 'Volume': [500, 600]  # 只有收盘价和成交量\n",
    "    })\n",
    "}\n",
    "\n",
    "# 使用'nan'策略\n",
    "aligned = Data.align_columns(data, missing='nan')\n",
    "print(aligned)  # 结果：GOOGL的Open, High, Low列为NaN\n",
    "\n",
    "# 使用'drop'策略  \n",
    "aligned = Data.align_columns(data, missing='drop')\n",
    "print(aligned)  # 结果：只保留Close和Volume列\n",
    "\n",
    "# 使用'raise'策略（默认）\n",
    "try:\n",
    "    aligned = Data.align_columns(data, missing='raise')\n",
    "except ValueError:\n",
    "    print(\"列结构不匹配，抛出异常\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select_symbol_kwargs\n",
    "对于字典 `kwargs` 中键为 `symbol_dict` 类型的那些项，保留存在于 `symbol` 的成分（如果不存在则删除该项）。\n",
    "```python\n",
    "@classmethod\n",
    "def select_symbol_kwargs(cls, symbol: tp.Label, kwargs: dict) -> dict:\n",
    "    \"\"\"Select keyword arguments belonging to `symbol`.\"\"\"\n",
    "    _kwargs = dict()\n",
    "    for k, v in kwargs.items():\n",
    "        if isinstance(v, symbol_dict):\n",
    "            if symbol in v:\n",
    "                _kwargs[k] = v[symbol]\n",
    "        else:\n",
    "            _kwargs[k] = v\n",
    "    return _kwargs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vectorbt.data.base import Data, symbol_dict\n",
    "\n",
    "kwargs = {\n",
    "    'start_date': '2020-01-01',\n",
    "    'period': symbol_dict({\n",
    "        'AAPL': '1y',\n",
    "        'GOOGL': '2y'\n",
    "    }),\n",
    "    'interval': symbol_dict({\n",
    "        'AAPL': '1d',\n",
    "        'GOOGL': '1h'\n",
    "    })\n",
    "}\n",
    "\n",
    "aapl_kwargs = Data.select_symbol_kwargs('AAPL', kwargs)\n",
    "print(aapl_kwargs)  # {'start_date': '2020-01-01', 'period': '1y', 'interval': '1d'}\n",
    "\n",
    "googl_kwargs = Data.select_symbol_kwargs('GOOGL', kwargs)\n",
    "print(googl_kwargs)  # {'start_date': '2020-01-01', 'period': '2y', 'interval': '1h'}\n",
    "\n",
    "msft_kwargs = Data.select_symbol_kwargs('MSFT', kwargs)\n",
    "print(msft_kwargs)  # {'start_date': '2020-01-01'}  # 只包含通用参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from_data\n",
    "根据参数：\n",
    "- `data`: 以符号为键的数据字典，值为类数组对象\n",
    "- `tz_localize`: `data` 的 `Index` 的时区\n",
    "- `tz_convert`: 要转换到的时区\n",
    "- `missing_index`: 索引缺失处理策略\n",
    "- `missing_columns`: 列缺失处理策略\n",
    "- `wrapper_kwargs`: 传递给ArrayWrapper的关键字参数\n",
    "- `**kwargs`: 传递给 `__init__` 方法的其他关键字参数\n",
    "\n",
    "构建一个新的 `type(调用者)` 类型的实例并返回。具体过程：\n",
    "- 对于 `data` 中的每一项，如果其 `index` 是 `DatetimeIndex` 并且无时区信息，从 `tz_localize` 转到 `tz_convert` 时区\n",
    "- 对齐 `data` 中各项的时间索引，以及列\n",
    "- 构建一个新的 `type(调用者)` 类型的实例并返回。\n",
    "```python\n",
    "@classmethod\n",
    "def from_data(cls: tp.Type[DataT],\n",
    "                data: tp.Data,\n",
    "                tz_localize: tp.Optional[tp.TimezoneLike] = None,\n",
    "                tz_convert: tp.Optional[tp.TimezoneLike] = None,\n",
    "                missing_index: tp.Optional[str] = None,\n",
    "                missing_columns: tp.Optional[str] = None,\n",
    "                wrapper_kwargs: tp.KwargsLike = None,\n",
    "                **kwargs) -> DataT:\n",
    "    from vectorbt._settings import settings\n",
    "    data_cfg = settings['data']\n",
    "\n",
    "    # Get global defaults\n",
    "    if tz_localize is None:\n",
    "        tz_localize = data_cfg['tz_localize']\n",
    "    if tz_convert is None:\n",
    "        tz_convert = data_cfg['tz_convert']\n",
    "    if missing_index is None:\n",
    "        missing_index = data_cfg['missing_index']\n",
    "    if missing_columns is None:\n",
    "        missing_columns = data_cfg['missing_columns']\n",
    "    if wrapper_kwargs is None:\n",
    "        wrapper_kwargs = {}\n",
    "\n",
    "    data = data.copy()\n",
    "    for k, v in data.items():\n",
    "        # Convert array to pandas\n",
    "        if not isinstance(v, (pd.Series, pd.DataFrame)):\n",
    "            v = np.asarray(v)\n",
    "            if v.ndim == 1:\n",
    "                v = pd.Series(v)\n",
    "            else:\n",
    "                v = pd.DataFrame(v)\n",
    "\n",
    "        # Perform operations with datetime-like index\n",
    "        if isinstance(v.index, pd.DatetimeIndex):\n",
    "            if tz_localize is not None:\n",
    "                if not is_tz_aware(v.index):\n",
    "                    v = v.tz_localize(to_timezone(tz_localize))\n",
    "            if tz_convert is not None:\n",
    "                v = v.tz_convert(to_timezone(tz_convert))\n",
    "            v.index.freq = v.index.inferred_freq\n",
    "        data[k] = v\n",
    "\n",
    "    # Align index and columns\n",
    "    data = cls.align_index(data, missing=missing_index)\n",
    "    data = cls.align_columns(data, missing=missing_columns)\n",
    "\n",
    "    # Create new instance\n",
    "    symbols = list(data.keys())\n",
    "    wrapper = ArrayWrapper.from_obj(data[symbols[0]], **wrapper_kwargs)\n",
    "    return cls(\n",
    "        wrapper,\n",
    "        data,\n",
    "        tz_localize=tz_localize,\n",
    "        tz_convert=tz_convert,\n",
    "        missing_index=missing_index,\n",
    "        missing_columns=missing_columns,\n",
    "        **kwargs\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vectorbt.data.base import Data\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    'AAPL': pd.Series([100, 101, 102], \n",
    "                        index=pd.date_range('2023-01-01', periods=3)),\n",
    "    'GOOGL': pd.Series([2000, 2010, 2020], \n",
    "                        index=pd.date_range('2023-01-01', periods=3))\n",
    "}\n",
    "data = Data.from_data(\n",
    "    data_dict,\n",
    "    tz_localize='UTC',      # 本地化为UTC\n",
    "    tz_convert='US/Eastern' # 转换为美东时间\n",
    ")\n",
    "\n",
    "print(data)\n",
    "print(data.data['AAPL'])\n",
    "print(data.data['GOOGL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download_symbol\n",
    "下载单个符号数据（例如 Yahoo Finance、Alpha Vantage 等）的抽象方法，必须在子类中实现具体的数据下载逻辑。\n",
    "- `Args`：\n",
    "  - `symbol (tp.Label)`：要下载的金融符号（如'AAPL', 'GOOGL'）\n",
    "  - `**kwargs`：下载参数，具体参数取决于数据源的要求\n",
    "- `Returns`：返回 `Series` 或 `DataFrame`，包含该符号的数据\n",
    "```python\n",
    "@classmethod\n",
    "def download_symbol(cls, symbol: tp.Label, **kwargs) -> tp.SeriesFrame:\n",
    "    raise NotImplementedError\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download\n",
    "使用 `download_symbol` 下载参数 `symbols` 对应的数据，然后使用 `from_data` 构建一个新的 `type(调用者)` 类型的实例并返回\n",
    "```python\n",
    "@classmethod\n",
    "def download(cls: tp.Type[DataT],\n",
    "                symbols: tp.Union[tp.Label, tp.Labels],\n",
    "                tz_localize: tp.Optional[tp.TimezoneLike] = None,\n",
    "                tz_convert: tp.Optional[tp.TimezoneLike] = None,\n",
    "                missing_index: tp.Optional[str] = None,\n",
    "                missing_columns: tp.Optional[str] = None,\n",
    "                wrapper_kwargs: tp.KwargsLike = None,\n",
    "                **kwargs) -> DataT:\n",
    "    if checks.is_hashable(symbols):\n",
    "        symbols = [symbols]\n",
    "    elif not checks.is_sequence(symbols):\n",
    "        raise TypeError(\"Symbols must be either hashable or sequence of hashable\")\n",
    "\n",
    "    data = dict()\n",
    "    for s in symbols:\n",
    "        _kwargs = cls.select_symbol_kwargs(s, kwargs)\n",
    "\n",
    "        data[s] = cls.download_symbol(s, **_kwargs)\n",
    "\n",
    "    return cls.from_data(\n",
    "        data,\n",
    "        tz_localize=tz_localize,\n",
    "        tz_convert=tz_convert,\n",
    "        missing_index=missing_index,\n",
    "        missing_columns=missing_columns,\n",
    "        wrapper_kwargs=wrapper_kwargs,\n",
    "        download_kwargs=kwargs\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update_symbol\n",
    "下载 `symbol` 对应符号的新数据的的抽象方法，需要在子类中实现具体的数据更新逻辑。\n",
    "```python\n",
    "def update_symbol(self, symbol: tp.Label, **kwargs) -> tp.SeriesFrame:\n",
    "    raise NotImplementedError\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update\n",
    "下载 `self.data` 中各符号的新数据来更新实例 `self`。具体过程：\n",
    "- 对于 `self.data` 中的每个符号 `(k: v)`\n",
    "  - 从 `kwargs` 挑选出对应的下载参数，使用 `update_symbol` 下载新的数据 `new_obj`\n",
    "  - 延续 `v` 的索引，然后与 `new_obj` 可以构成新的 Series/DataFrame\n",
    "    - 如果索引是 `DatetimeIndex` 并且无时区信息，从 `self.tz_localize` 转到 `self.tz_convert` 时区\n",
    "  - 将 `new_obj` 存到 `new_data[k]`\n",
    "- 对齐 `new_data` 中各项的时间索引，以及列\n",
    "- 合并旧数据和新数据，对于 `self.data` 和 `new_data` 中的每个符号\n",
    "  - 确保结构一致：从 `new_data[k]` 中取出 `self.data[k].name/self.data[k].columns` 对应的\n",
    "  - 纵向连接，取出重复索引，保留最新的，重新赋给　`new_data[k]`\n",
    "- 使用 `Configured.replace` 更新实例\n",
    "```python\n",
    "def update(self: DataT, **kwargs) -> DataT:\n",
    "    new_data = dict()\n",
    "    for k, v in self.data.items():\n",
    "        _kwargs = self.select_symbol_kwargs(k, kwargs)\n",
    "        new_obj = self.update_symbol(k, **_kwargs)\n",
    "\n",
    "        if not isinstance(new_obj, (pd.Series, pd.DataFrame)):\n",
    "            new_obj = np.asarray(new_obj)\n",
    "            index = pd.RangeIndex(\n",
    "                start=v.index[-1],\n",
    "                stop=v.index[-1] + new_obj.shape[0],\n",
    "                step=1\n",
    "            )\n",
    "            if new_obj.ndim == 1:\n",
    "                new_obj = pd.Series(new_obj, index=index)\n",
    "            else:\n",
    "                new_obj = pd.DataFrame(new_obj, index=index)\n",
    "\n",
    "        if isinstance(new_obj.index, pd.DatetimeIndex):\n",
    "            if self.tz_localize is not None:\n",
    "                if not is_tz_aware(new_obj.index):\n",
    "                    new_obj = new_obj.tz_localize(to_timezone(self.tz_localize))\n",
    "            if self.tz_convert is not None:\n",
    "                new_obj = new_obj.tz_convert(to_timezone(self.tz_convert))\n",
    "\n",
    "        new_data[k] = new_obj\n",
    "\n",
    "    new_data = self.align_index(new_data, missing=self.missing_index)\n",
    "    new_data = self.align_columns(new_data, missing=self.missing_columns)\n",
    "\n",
    "    for k, v in new_data.items():\n",
    "        if isinstance(self.data[k], pd.Series):\n",
    "            if isinstance(v, pd.DataFrame):\n",
    "                v = v[self.data[k].name]\n",
    "        else:\n",
    "            v = v[self.data[k].columns]\n",
    "        v = pd.concat((self.data[k], v), axis=0)\n",
    "        v = v[~v.index.duplicated(keep='last')]\n",
    "        if isinstance(v.index, pd.DatetimeIndex):\n",
    "            v.index.freq = v.index.inferred_freq\n",
    "        new_data[k] = v\n",
    "\n",
    "    new_index = new_data[self.symbols[0]].index\n",
    "    return self.replace(\n",
    "        wrapper=self.wrapper.replace(index=new_index),\n",
    "        data=new_data\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat\n",
    "对于多符号数据 `self.data`，返回其以列名为键的字典。例如：\n",
    "```python\n",
    "data.data = {\n",
    "    'AAPL': pd.DataFrame({\n",
    "        'Open': [100, 101], 'Close': [101, 102], 'Volume': [1000, 1100]\n",
    "    }),\n",
    "    'GOOGL': pd.DataFrame({\n",
    "        'Open': [2000, 2010], 'Close': [2010, 2020], 'Volume': [500, 600]\n",
    "    })\n",
    "}\n",
    "concat_data = data.concat()\n",
    "# 结果：\n",
    "# {\n",
    "#     'Open': DataFrame with columns ['AAPL', 'GOOGL'],\n",
    "#     'Close': DataFrame with columns ['AAPL', 'GOOGL'], \n",
    "#     'Volume': DataFrame with columns ['AAPL', 'GOOGL']\n",
    "# }\n",
    "```\n",
    "\n",
    "```python\n",
    "@cached_method\n",
    "def concat(self, level_name: str = 'symbol') -> tp.Data:\n",
    "    first_data = self.data[self.symbols[0]]\n",
    "    index = first_data.index\n",
    "    if isinstance(first_data, pd.Series):\n",
    "        columns = pd.Index([first_data.name])\n",
    "    else:\n",
    "        columns = first_data.columns\n",
    "    if len(self.symbols) > 1:\n",
    "        new_data = {c: pd.DataFrame(\n",
    "            index=index,\n",
    "            columns=pd.Index(self.symbols, name=level_name)\n",
    "        ) for c in columns}\n",
    "    else:\n",
    "        new_data = {c: pd.Series(\n",
    "            index=index,\n",
    "            name=self.symbols[0]\n",
    "        ) for c in columns}\n",
    "    for c in columns:\n",
    "        for s in self.symbols:\n",
    "            if isinstance(self.data[s], pd.Series):\n",
    "                col_data = self.data[s]\n",
    "            else:\n",
    "                col_data = self.data[s][c]\n",
    "            if len(self.symbols) > 1:\n",
    "                new_data[c].loc[:, s] = col_data\n",
    "            else:\n",
    "                new_data[c].loc[:] = col_data\n",
    "    for c in columns:\n",
    "        new_data[c] = new_data[c].infer_objects()\n",
    "    return new_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get\n",
    "获取 `self.data` 中 `column` 对应的数据。具体逻辑：\n",
    "- 只有一个符号\n",
    "  - `column` 空，返回该符号的整个数据\n",
    "  - `column` 不空，返回该符号的 `column` 列数据\n",
    "- 使用 `concat` 返回 `self.data` 的以列名为键的字典\n",
    "  - 只有一个键值对：返回对应的值\n",
    "  - 多于一个键值对\n",
    "    - `column` 空\n",
    "      - 将所有值构成一个元组返回\n",
    "    - `column` 不空且为 `list`\n",
    "      - 取出键在 `column` 中的值，构成一个元组返回\n",
    "    - 否则\n",
    "      - 返回 `column` 对应的值\n",
    "```python\n",
    "def get(self, column: tp.Optional[tp.Label] = None, **kwargs) -> tp.MaybeTuple[tp.SeriesFrame]:\n",
    "    if len(self.symbols) == 1:\n",
    "        if column is None:\n",
    "            return self.data[self.symbols[0]]\n",
    "        return self.data[self.symbols[0]][column]\n",
    "\n",
    "    concat_data = self.concat(**kwargs)\n",
    "    if len(concat_data) == 1:\n",
    "        return tuple(concat_data.values())[0]\n",
    "    if column is not None:\n",
    "        if isinstance(column, list):\n",
    "            return tuple([concat_data[c] for c in column])\n",
    "        return concat_data[column]\n",
    "    return tuple(concat_data.values())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stats_defaults\n",
    "返回的是 `merge_dicts(settings['stats_builder'], dict(settings=dict(freq=self.wrapper.freq)), settings['data']['stats'])`。\n",
    "```python\n",
    "@property\n",
    "def stats_defaults(self) -> tp.Kwargs:\n",
    "    from vectorbt._settings import settings\n",
    "    data_stats_cfg = settings['data']['stats']\n",
    "\n",
    "    return merge_dicts(\n",
    "        StatsBuilderMixin.stats_defaults.__get__(self),\n",
    "        data_stats_cfg\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plots_defaults\n",
    "返回的是 `merge_dicts(settings['plots_builder'], dict(settings=dict(freq=self.wrapper.freq)), settings['data']['plots'])`。\n",
    "```python\n",
    "@property\n",
    "def plots_defaults(self) -> tp.Kwargs:\n",
    "    from vectorbt._settings import settings\n",
    "    data_plots_cfg = settings['data']['plots']\n",
    "\n",
    "    return merge_dicts(\n",
    "        PlotsBuilderMixin.plots_defaults.__get__(self),\n",
    "        data_plots_cfg\n",
    "    )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_vectorbt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
