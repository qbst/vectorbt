{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类继承关系\n",
    "```mermaid\n",
    "classDiagram\n",
    "    class Configured\n",
    "    class PandasIndexer\n",
    "    class ColumnGrouper\n",
    "    class ArrayWrapper\n",
    "    class Wrapping\n",
    "    \n",
    "    Configured <|-- ArrayWrapper\n",
    "    PandasIndexer <|-- ArrayWrapper\n",
    "    Configured <|-- Wrapping\n",
    "    PandasIndexer <|-- Wrapping\n",
    "    AttrResolver <|-- Wrapping\n",
    "\n",
    "    ArrayWrapper o-- ColumnGrouper : has\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class ArrayWrapper(Configured, PandasIndexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__init__`\n",
    "```python\n",
    "    def __init__(self,\n",
    "                 index: tp.IndexLike,                           # 行索引，支持类似pandas索引的对象\n",
    "                 columns: tp.IndexLike,                         # 列索引，支持类似pandas索引的对象\n",
    "                 ndim: int,                      # 数组维度数量，通常为1（Series）或2（DataFrame）\n",
    "                 freq: tp.Optional[tp.FrequencyLike] = None,    # 时间序列频率，可选\n",
    "                 column_only_select: tp.Optional[bool] = None,  # 是否仅对列进行索引，可选\n",
    "                 group_select: tp.Optional[bool] = None,        # 是否对分组进行索引，可选\n",
    "                 grouped_ndim: tp.Optional[int] = None,         # 分组后的维度数量，可选\n",
    "                 **kwargs) -> None:                             # 传递给ColumnGrouper的额外参数\n",
    "        config = dict(\n",
    "            index=index,\n",
    "            columns=columns,\n",
    "            ndim=ndim,\n",
    "            freq=freq,\n",
    "            column_only_select=column_only_select,\n",
    "            group_select=group_select,\n",
    "            grouped_ndim=grouped_ndim,\n",
    "        )\n",
    "\n",
    "        checks.assert_not_none(index)\n",
    "        checks.assert_not_none(columns)\n",
    "        checks.assert_not_none(ndim)\n",
    "        \n",
    "        if not isinstance(index, pd.Index):\n",
    "            index = pd.Index(index) \n",
    "        if not isinstance(columns, pd.Index):\n",
    "            columns = pd.Index(columns) \n",
    "\n",
    "        self._index = index \n",
    "        self._columns = columns\n",
    "        self._ndim = ndim\n",
    "        self._freq = freq\n",
    "        self._column_only_select = column_only_select\n",
    "        self._group_select = group_select\n",
    "        self._grouper = ColumnGrouper(columns, **kwargs)\n",
    "        self._grouped_ndim = grouped_ndim\n",
    "\n",
    "        PandasIndexer.__init__(self) \n",
    "        Configured.__init__(self, **merge_dicts(config, self._grouper._config)) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings['array_wrapper']\n",
    "```python\n",
    "array_wrapper=dict(\n",
    "    column_only_select=False,  # 不仅选择列\n",
    "    group_select=True,  # 启用组选择\n",
    "    freq=None,  # 频率默认为None\n",
    "    silence_warnings=False  # 不静默警告\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regroup\n",
    "核心是：基于当前的 `self` 构建一个新的 `ArrayWrapper`：使用参数 `group_by` 重新选择 `self.columns` 来构建 `.grouper`。\n",
    "\n",
    "当 \n",
    "- `self.grouper.group_by` 是否和 `group_by` 不完全一致\n",
    "- 且二者情况符合：`self.allow_enable, self.allow_disable, self.allow_modify`\n",
    "\n",
    "使用 `self.__dict__` 和 `group_by` 重新构建一个 `ArrayWrapper` 返回。否则返回 `self`。\n",
    "```python\n",
    "def regroup(self: ArrayWrapperT, group_by: tp.GroupByLike, **kwargs) -> ArrayWrapperT:\n",
    "    if self.grouper.is_grouping_changed(group_by=group_by):\n",
    "        self.grouper.check_group_by(group_by=group_by)\n",
    "        grouped_ndim = None\n",
    "        if self.grouper.is_grouped(group_by=group_by):\n",
    "            if not self.grouper.is_group_count_changed(group_by=group_by):\n",
    "                grouped_ndim = self.grouped_ndim\n",
    "        return self.replace(grouped_ndim=grouped_ndim, group_by=group_by, **kwargs)\n",
    "    return self\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resolve\n",
    "使用参数 `group_by` 重新选择 `self.columns` 来构建 `.grouper`，从而生成一个新的 `ArrayWrapper` 实例 `_self`\n",
    "\n",
    "取出 `_self.grouper.group_by` 的去重元素作为 `columns`。\n",
    "\n",
    "使用 `columns` 和 `group_by = None` 重新构建一个 `ArrayWrapper` 实例返回。\n",
    "\n",
    "```python\n",
    "@cached_method\n",
    "def resolve(self: ArrayWrapperT, group_by: tp.GroupByLike = None, **kwargs) -> ArrayWrapperT:\n",
    "    _self = self.regroup(group_by=group_by, **kwargs)\n",
    "    if _self.grouper.is_grouped():\n",
    "        return _self.replace(\n",
    "            columns=_self.grouper.get_columns(),\n",
    "            ndim=_self.grouped_ndim,\n",
    "            grouped_ndim=None,\n",
    "            group_by=None\n",
    "        )\n",
    "    return _self\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wrap\n",
    "```python\n",
    "def wrap(self,\n",
    "            arr: tp.ArrayLike,\n",
    "            index: tp.Optional[tp.IndexLike] = None,\n",
    "            columns: tp.Optional[tp.IndexLike] = None,\n",
    "            fillna: tp.Optional[tp.Scalar] = None,\n",
    "            dtype: tp.Optional[tp.PandasDTypeLike] = None,\n",
    "            group_by: tp.GroupByLike = None,\n",
    "            to_timedelta: bool = False,\n",
    "            to_index: bool = False,\n",
    "            silence_warnings: tp.Optional[bool] = None) -> tp.SeriesFrame:\n",
    "\n",
    "    from vectorbt._settings import settings\n",
    "    array_wrapper_cfg = settings['array_wrapper']\n",
    "\n",
    "    if silence_warnings is None:\n",
    "        silence_warnings = array_wrapper_cfg['silence_warnings']\n",
    "\n",
    "    _self = self.resolve(group_by=group_by)\n",
    "\n",
    "    if index is None:\n",
    "        index = _self.index\n",
    "    if not isinstance(index, pd.Index):\n",
    "        index = pd.Index(index)\n",
    "    if columns is None:\n",
    "        columns = _self.columns\n",
    "    if not isinstance(columns, pd.Index):\n",
    "        columns = pd.Index(columns)\n",
    "    if len(columns) == 1:\n",
    "        name = columns[0]\n",
    "        if name == 0:  # was a Series before\n",
    "            name = None\n",
    "    else:\n",
    "        name = None\n",
    "\n",
    "    def _wrap(arr):\n",
    "        arr = np.asarray(arr)\n",
    "        checks.assert_ndim(arr, (1, 2))\n",
    "        if fillna is not None:\n",
    "            arr[pd.isnull(arr)] = fillna\n",
    "        arr = reshape_fns.soft_to_ndim(arr, self.ndim)\n",
    "        checks.assert_shape_equal(arr, index, axis=(0, 0))\n",
    "        if arr.ndim == 2:\n",
    "            checks.assert_shape_equal(arr, columns, axis=(1, 0))\n",
    "        if arr.ndim == 1:\n",
    "            return pd.Series(arr, index=index, name=name, dtype=dtype)\n",
    "        if arr.ndim == 2:\n",
    "            if arr.shape[1] == 1 and _self.ndim == 1:\n",
    "                return pd.Series(arr[:, 0], index=index, name=name, dtype=dtype)\n",
    "            return pd.DataFrame(arr, index=index, columns=columns, dtype=dtype)\n",
    "        raise ValueError(f\"{arr.ndim}-d input is not supported\")\n",
    "\n",
    "    out = _wrap(arr)\n",
    "    if to_index:\n",
    "        # Convert to index\n",
    "        if checks.is_series(out):\n",
    "            out = out.map(lambda x: self.index[x] if x != -1 else np.nan)\n",
    "        else:\n",
    "            out = out.applymap(lambda x: self.index[x] if x != -1 else np.nan)\n",
    "    if to_timedelta:\n",
    "        # Convert to timedelta\n",
    "        out = self.to_timedelta(out, silence_warnings=silence_warnings)\n",
    "    return out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wrap_reduced\n",
    "```python\n",
    "def wrap_reduced(self,\n",
    "                    arr: tp.ArrayLike,\n",
    "                    name_or_index: tp.NameIndex = None,\n",
    "                    columns: tp.Optional[tp.IndexLike] = None,\n",
    "                    fillna: tp.Optional[tp.Scalar] = None,\n",
    "                    dtype: tp.Optional[tp.PandasDTypeLike] = None,\n",
    "                    group_by: tp.GroupByLike = None,\n",
    "                    to_timedelta: bool = False,\n",
    "                    to_index: bool = False,\n",
    "                    silence_warnings: tp.Optional[bool] = None) -> tp.MaybeSeriesFrame:\n",
    "    \"\"\"Wrap result of reduction.\n",
    "\n",
    "    `name_or_index` can be the name of the resulting series if reducing to a scalar per column,\n",
    "    or the index of the resulting series/dataframe if reducing to an array per column.\n",
    "    `columns` can be set to override object's default columns.\n",
    "\n",
    "    See `ArrayWrapper.wrap` for the pipeline.\"\"\"\n",
    "    from vectorbt._settings import settings\n",
    "    array_wrapper_cfg = settings['array_wrapper']\n",
    "\n",
    "    if silence_warnings is None:\n",
    "        silence_warnings = array_wrapper_cfg['silence_warnings']\n",
    "\n",
    "    checks.assert_not_none(self.ndim)\n",
    "    _self = self.resolve(group_by=group_by)\n",
    "\n",
    "    if columns is None:\n",
    "        columns = _self.columns\n",
    "    if not isinstance(columns, pd.Index):\n",
    "        columns = pd.Index(columns)\n",
    "\n",
    "    if to_index:\n",
    "        if dtype is None:\n",
    "            dtype = np.int64\n",
    "        if fillna is None:\n",
    "            fillna = -1\n",
    "\n",
    "    def _wrap_reduced(arr):\n",
    "        nonlocal name_or_index\n",
    "\n",
    "        arr = np.asarray(arr)\n",
    "        if fillna is not None:\n",
    "            arr[pd.isnull(arr)] = fillna\n",
    "        if arr.ndim == 0:\n",
    "            # Scalar per Series/DataFrame\n",
    "            return pd.Series(arr, dtype=dtype)[0]\n",
    "        if arr.ndim == 1:\n",
    "            if _self.ndim == 1:\n",
    "                if arr.shape[0] == 1:\n",
    "                    # Scalar per Series/DataFrame with one column\n",
    "                    return pd.Series(arr, dtype=dtype)[0]\n",
    "                # Array per Series\n",
    "                sr_name = columns[0]\n",
    "                if sr_name == 0:  # was arr Series before\n",
    "                    sr_name = None\n",
    "                if isinstance(name_or_index, str):\n",
    "                    name_or_index = None\n",
    "                return pd.Series(arr, index=name_or_index, name=sr_name, dtype=dtype)\n",
    "            # Scalar per column in arr DataFrame\n",
    "            return pd.Series(arr, index=columns, name=name_or_index, dtype=dtype)\n",
    "        if arr.ndim == 2:\n",
    "            if arr.shape[1] == 1 and _self.ndim == 1:\n",
    "                arr = reshape_fns.soft_to_ndim(arr, 1)\n",
    "                # Array per Series\n",
    "                sr_name = columns[0]\n",
    "                if sr_name == 0:  # was arr Series before\n",
    "                        sr_name = None\n",
    "                    if isinstance(name_or_index, str):\n",
    "                        name_or_index = None\n",
    "                    return pd.Series(arr, index=name_or_index, name=sr_name, dtype=dtype)\n",
    "                # Array per column in DataFrame\n",
    "                if isinstance(name_or_index, str):\n",
    "                    name_or_index = None\n",
    "                return pd.DataFrame(arr, index=name_or_index, columns=columns, dtype=dtype)\n",
    "            raise ValueError(f\"{arr.ndim}-d input is not supported\")\n",
    "\n",
    "        out = _wrap_reduced(arr)\n",
    "        if to_index:\n",
    "            # Convert to index\n",
    "            if checks.is_series(out):\n",
    "                out = out.map(lambda x: self.index[x] if x != -1 else np.nan)\n",
    "            elif checks.is_frame(out):\n",
    "                out = out.applymap(lambda x: self.index[x] if x != -1 else np.nan)\n",
    "            else:\n",
    "                out = self.index[out] if out != -1 else np.nan\n",
    "        if to_timedelta:\n",
    "            # Convert to timedelta\n",
    "            out = self.to_timedelta(out, silence_warnings=silence_warnings)\n",
    "        return out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indexing_func_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "@cached_method\n",
    "def indexing_func_meta(self: ArrayWrapperT,\n",
    "                        pd_indexing_func: tp.PandasIndexingFunc,\n",
    "                        index: tp.Optional[tp.IndexLike] = None,\n",
    "                        columns: tp.Optional[tp.IndexLike] = None,\n",
    "                        column_only_select: tp.Optional[bool] = None,\n",
    "                        group_select: tp.Optional[bool] = None,\n",
    "                        group_by: tp.GroupByLike = None) -> IndexingMetaT:\n",
    "    from vectorbt._settings import settings\n",
    "    array_wrapper_cfg = settings['array_wrapper']\n",
    "\n",
    "    if column_only_select is None:\n",
    "        column_only_select = self.column_only_select\n",
    "    if column_only_select is None:\n",
    "        column_only_select = array_wrapper_cfg['column_only_select']\n",
    "    if group_select is None:\n",
    "        group_select = self.group_select\n",
    "    if group_select is None:\n",
    "        group_select = array_wrapper_cfg['group_select']\n",
    "        \n",
    "    _self = self.regroup(group_by)\n",
    "    group_select = group_select and _self.grouper.is_grouped()\n",
    "    if index is None:\n",
    "        index = _self.index\n",
    "    if not isinstance(index, pd.Index):\n",
    "        index = pd.Index(index)\n",
    "    if columns is None:\n",
    "        if group_select:\n",
    "            columns = _self.grouper.get_columns()\n",
    "        else:\n",
    "            columns = _self.columns\n",
    "    if not isinstance(columns, pd.Index):\n",
    "        columns = pd.Index(columns)\n",
    "    if group_select:\n",
    "        # Groups as columns\n",
    "        i_wrapper = ArrayWrapper(index, columns, _self.get_ndim())\n",
    "    else:\n",
    "        # Columns as columns\n",
    "        i_wrapper = ArrayWrapper(index, columns, _self.ndim)\n",
    "    n_rows = len(index)\n",
    "    n_cols = len(columns)\n",
    "\n",
    "    if column_only_select:\n",
    "        if i_wrapper.ndim == 1:\n",
    "            raise IndexingError(\"Columns only: This object already contains one column of data\")\n",
    "        try:\n",
    "            col_mapper = pd_indexing_func(i_wrapper.wrap_reduced(np.arange(n_cols), columns=columns))\n",
    "        except pd.core.indexing.IndexingError as e:\n",
    "            warnings.warn(\"Columns only: Make sure to treat this object \"\n",
    "                            \"as a Series of columns rather than a DataFrame\", stacklevel=2)\n",
    "            raise e\n",
    "        if checks.is_series(col_mapper):\n",
    "            new_columns = col_mapper.index\n",
    "            col_idxs = col_mapper.values\n",
    "            new_ndim = 2\n",
    "        else:\n",
    "            new_columns = columns[[col_mapper]]\n",
    "            col_idxs = col_mapper\n",
    "            new_ndim = 1\n",
    "        new_index = index\n",
    "        idx_idxs = np.arange(len(index))\n",
    "    else:\n",
    "        idx_mapper = pd_indexing_func(i_wrapper.wrap(\n",
    "            np.broadcast_to(np.arange(n_rows)[:, None], (n_rows, n_cols)),\n",
    "            index=index,\n",
    "            columns=columns\n",
    "        ))\n",
    "        if i_wrapper.ndim == 1:\n",
    "            if not checks.is_series(idx_mapper):\n",
    "                raise IndexingError(\"Selection of a scalar is not allowed\")\n",
    "            idx_idxs = idx_mapper.values\n",
    "            col_idxs = 0\n",
    "        else:\n",
    "            col_mapper = pd_indexing_func(i_wrapper.wrap(\n",
    "                np.broadcast_to(np.arange(n_cols), (n_rows, n_cols)),\n",
    "                index=index,\n",
    "                columns=columns\n",
    "            ))\n",
    "            if checks.is_frame(idx_mapper):\n",
    "                idx_idxs = idx_mapper.values[:, 0]\n",
    "                col_idxs = col_mapper.values[0]\n",
    "            elif checks.is_series(idx_mapper):\n",
    "                one_col = np.all(col_mapper.values == col_mapper.values.item(0))\n",
    "                one_idx = np.all(idx_mapper.values == idx_mapper.values.item(0))\n",
    "                if one_col and one_idx:\n",
    "                    # One index and one column selected, multiple times\n",
    "                    raise IndexingError(\"Must select at least two unique indices in one of both axes\")\n",
    "                elif one_col:\n",
    "                    # One column selected\n",
    "                    idx_idxs = idx_mapper.values\n",
    "                    col_idxs = col_mapper.values[0]\n",
    "                elif one_idx:\n",
    "                    # One index selected\n",
    "                    idx_idxs = idx_mapper.values[0]\n",
    "                    col_idxs = col_mapper.values\n",
    "                else:\n",
    "                    raise IndexingError\n",
    "            else:\n",
    "                raise IndexingError(\"Selection of a scalar is not allowed\")\n",
    "        new_index = index_fns.get_index(idx_mapper, 0)\n",
    "        if not isinstance(idx_idxs, np.ndarray):\n",
    "            # One index selected\n",
    "            new_columns = index[[idx_idxs]]\n",
    "        elif not isinstance(col_idxs, np.ndarray):\n",
    "            # One column selected\n",
    "            new_columns = columns[[col_idxs]]\n",
    "        else:\n",
    "            new_columns = index_fns.get_index(idx_mapper, 1)\n",
    "        new_ndim = idx_mapper.ndim\n",
    "\n",
    "    if _self.grouper.is_grouped():\n",
    "        # Grouping enabled\n",
    "        if np.asarray(idx_idxs).ndim == 0:\n",
    "            raise IndexingError(\"Flipping index and columns is not allowed\")\n",
    "\n",
    "        if group_select:\n",
    "            # Selection based on groups\n",
    "            # Get indices of columns corresponding to selected groups\n",
    "            group_idxs = col_idxs\n",
    "            group_idxs_arr = reshape_fns.to_1d_array(group_idxs)\n",
    "            group_start_idxs = _self.grouper.get_group_start_idxs()[group_idxs_arr]\n",
    "            group_end_idxs = _self.grouper.get_group_end_idxs()[group_idxs_arr]\n",
    "            ungrouped_col_idxs = get_ranges_arr(group_start_idxs, group_end_idxs)\n",
    "            ungrouped_columns = _self.columns[ungrouped_col_idxs]\n",
    "            if new_ndim == 1 and len(ungrouped_columns) == 1:\n",
    "                ungrouped_ndim = 1\n",
    "                ungrouped_col_idxs = ungrouped_col_idxs[0]\n",
    "            else:\n",
    "                ungrouped_ndim = 2\n",
    "\n",
    "            # Get indices of selected groups corresponding to the new columns\n",
    "            # We could do _self.group_by[ungrouped_col_idxs] but indexing operation may have changed the labels\n",
    "            group_lens = _self.grouper.get_group_lens()[group_idxs_arr]\n",
    "            ungrouped_group_idxs = np.full(len(ungrouped_columns), 0)\n",
    "            ungrouped_group_idxs[group_lens[:-1]] = 1\n",
    "            ungrouped_group_idxs = np.cumsum(ungrouped_group_idxs)\n",
    "\n",
    "            return _self.replace(\n",
    "                index=new_index,\n",
    "                columns=ungrouped_columns,\n",
    "                ndim=ungrouped_ndim,\n",
    "                grouped_ndim=new_ndim,\n",
    "                group_by=new_columns[ungrouped_group_idxs]\n",
    "            ), idx_idxs, group_idxs, ungrouped_col_idxs\n",
    "\n",
    "        # Selection based on columns\n",
    "        col_idxs_arr = reshape_fns.to_1d_array(col_idxs)\n",
    "        return _self.replace(\n",
    "            index=new_index,\n",
    "            columns=new_columns,\n",
    "            ndim=new_ndim,\n",
    "            grouped_ndim=None,\n",
    "            group_by=_self.grouper.group_by[col_idxs_arr]\n",
    "        ), idx_idxs, col_idxs, col_idxs\n",
    "\n",
    "    # Grouping disabled\n",
    "    return _self.replace(\n",
    "        index=new_index,\n",
    "        columns=new_columns,\n",
    "        ndim=new_ndim,\n",
    "        grouped_ndim=None,\n",
    "        group_by=None\n",
    "    ), idx_idxs, col_idxs, col_idxs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class Wrapping(Configured, PandasIndexer, AttrResolver)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
